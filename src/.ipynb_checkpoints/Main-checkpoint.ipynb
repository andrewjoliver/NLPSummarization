{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import empty\n",
    "import numpy as np\n",
    "import csv\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    stop_words = [\"a\", \"about\", \"above\", \"after\", \"again\", \"against\", \"ain\", \"all\", \"am\", \"an\", \"and\", \"any\", \"are\", \"aren\", \"aren't\", \"as\", \"at\", \"be\", \"because\", \"been\", \"before\", \"being\", \"below\", \"between\", \"both\", \"but\", \"by\", \"can\", \"couldn\", \"couldn't\", \"d\", \"did\", \"didn\", \"didn't\", \"do\", \"does\", \"doesn\", \"doesn't\", \"doing\", \"don\", \"don't\", \"down\", \"during\", \"each\", \"few\", \"for\", \"from\", \"further\", \"had\", \"hadn\", \"hadn't\", \"has\", \"hasn\", \"hasn't\", \"have\", \"haven\", \"haven't\", \"having\", \"he\", \"her\", \"here\", \"hers\", \"herself\", \"him\", \"himself\", \"his\", \"how\", \"i\", \"if\", \"in\", \"into\", \"is\", \"isn\", \"isn't\", \"it\", \"it's\", \"its\", \"itself\", \"just\", \"ll\", \"m\", \"ma\", \"me\", \"mightn\", \"mightn't\", \"more\", \"most\", \"mustn\", \"mustn't\", \"my\", \"myself\", \"needn\", \"needn't\", \"no\", \"nor\", \"not\", \"now\", \"o\", \"of\", \"off\", \"on\", \"once\", \"only\", \"or\", \"other\", \"our\", \"ours\", \"ourselves\", \"out\", \"over\", \"own\", \"re\", \"s\", \"same\", \"shan\", \"shan't\", \"she\", \"she's\", \"should\", \"should've\", \"shouldn\", \"shouldn't\", \"so\", \"some\", \"such\", \"t\", \"than\", \"that\", \"that'll\", \"the\", \"their\", \"theirs\", \"them\", \"themselves\", \"then\", \"there\", \"these\", \"they\", \"this\", \"those\", \"through\", \"to\", \"too\", \"under\", \"until\", \"up\", \"ve\", \"very\", \"was\", \"wasn\", \"wasn't\", \"we\", \"were\", \"weren\", \"weren't\", \"what\", \"when\", \"where\", \"which\", \"while\", \"who\", \"whom\", \"why\", \"will\", \"with\", \"won\", \"won't\", \"wouldn\", \"wouldn't\", \"y\", \"you\", \"you'd\", \"you'll\", \"you're\", \"you've\", \"your\", \"yours\", \"yourself\", \"yourselves\", \"could\", \"he'd\", \"he'll\", \"he's\", \"here's\", \"how's\", \"i'd\", \"i'll\", \"i'm\", \"i've\", \"let's\", \"ought\", \"she'd\", \"she'll\", \"that's\", \"there's\", \"they'd\", \"they'll\", \"they're\", \"they've\", \"we'd\", \"we'll\", \"we're\", \"we've\", \"what's\", \"when's\", \"where's\", \"who's\", \"why's\", \"would\"]\n",
    "    punctuation = [\".\", \"-\", \"_\", \",\", \"<\", \">\", \"?\", \"/\", \"'\", \"\\\"\", \";\", \":\", \"[\", \"{\", \"}\", \"]\", \"\\\\\", \"|\", \"`\", \"~\", \"!\", \"@\", \"#\", \"$\", \"^\", \"&\", \"*\", \"(\", \")\"]\n",
    "    cleaned_text = list()\n",
    "\n",
    "    words = text.split(\" \")\n",
    "    for word in words:\n",
    "        word = word.lower()\n",
    "        for char in punctuation:\n",
    "            word = word.replace(char, ' ')\n",
    "                \n",
    "        if word not in stop_words and len(word) > 0:\n",
    "            cleaned_text.append(word)\n",
    "\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_full(read_loc):\n",
    "    gatsby = list()\n",
    "    gatsby_map = list()\n",
    "\n",
    "    with open(read_loc) as read_loc:\n",
    "        lines = read_loc.readlines()\n",
    "        \n",
    "    for line in lines:\n",
    "        if line == '\\n':\n",
    "            gatsby.append(\" paragraph-break-here \")\n",
    "        else:\n",
    "            gatsby.append(line.replace('\\n', ' '))\n",
    "\n",
    "    gatsby = \"\".join(gatsby)\n",
    "    gatsby = gatsby.split(\" paragraph-break-here \")\n",
    "\n",
    "    for line in gatsby:\n",
    "        cleaned_text_res = clean_text(line)\n",
    "        if len(cleaned_text_res) > 0:\n",
    "            gatsby_map.append((line, cleaned_text_res))\n",
    "\n",
    "    return gatsby_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gatsby_map = clean_full(\"../files/gatsby.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(paragraph1, paragraph2):\n",
    "    all_words = list()\n",
    "    for word in paragraph1:\n",
    "        all_words.append(word)\n",
    "    for word in paragraph2:\n",
    "        if word not in all_words:\n",
    "            all_words.append(word)\n",
    "    \n",
    "    all_words.sort()\n",
    "    \n",
    "    paragraph1vector = list()\n",
    "    paragraph2vector = list()\n",
    "\n",
    "    for word in all_words:\n",
    "        paragraph1vector.append(1) if word in paragraph1 else paragraph1vector.append(0)\n",
    "        paragraph2vector.append(1) if word in paragraph2 else paragraph2vector.append(0)\n",
    "    \n",
    "    sum = 0\n",
    "    for x in range(len(paragraph1vector)):\n",
    "        sum += paragraph1vector[x] * paragraph2vector[x]\n",
    "    \n",
    "    magnitudeA = 0\n",
    "    innerSquareSum = 0\n",
    "    for val in paragraph1vector:\n",
    "        innerSquareSum += val*val\n",
    "    magnitudeA = math.sqrt(innerSquareSum) \n",
    "    \n",
    "    magnitudeB = 0\n",
    "    innerSquareSum = 0\n",
    "    for val in paragraph2vector:\n",
    "        innerSquareSum += val*val\n",
    "    magnitudeB = math.sqrt(innerSquareSum) \n",
    "    \n",
    "    if (magnitudeA) == 0:\n",
    "        magnitudeA = 1\n",
    "\n",
    "    if (magnitudeB) == 0:\n",
    "        magnitudeB = 1\n",
    "\n",
    "    cosine_sim_val = float(sum) / float(magnitudeA*magnitudeB)\n",
    "    \n",
    "    if not isinstance(cosine_sim_val, float) or cosine_sim_val < 1e-5:\n",
    "        cosine_sim_val = 0.0\n",
    "    \n",
    "    return cosine_sim_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_matrix(paragraph_list):\n",
    "    n = len(paragraph_list)\n",
    "    adjacency_matrix = empty([n,n])\n",
    "    \n",
    "    for x in range(n):\n",
    "        for y in range(n):\n",
    "            cos_sim = cosine_similarity(paragraph_list[x][1], paragraph_list[y][1])\n",
    "            adjacency_matrix[x][y] = cos_sim\n",
    "\n",
    "    return adjacency_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         1.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         1.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 1.         0.03179815 0.05391639]\n",
      " [0.         0.         0.         ... 0.02990743 1.         0.        ]\n",
      " [0.         0.         0.         ... 0.05391639 0.         1.        ]]\n"
     ]
    }
   ],
   "source": [
    "adjacency_matrix = build_matrix(gatsby_map)\n",
    "print(adjacency_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_stationary_probabilities(adjacency_matrix):\n",
    "    # Code pulled from Duke University, Stats 663 from Dr. Cliburn Chan\n",
    "    # http://people.duke.edu/~ccc14/sta-663-2016/homework/Homework02_Solutions.html#Part-3:-Option-2:-Using-numpy.linalg-with-transpose-to-get-the-left-eigenvectors\n",
    "    P = adjacency_matrix/np.sum(adjacency_matrix, 1)[:, np.newaxis]\n",
    "    P5000 = np.linalg.matrix_power(P, 5000)\n",
    "    P5001 = np.dot(P5000, P)\n",
    "    # check that P50 is stationary\n",
    "    np.testing.assert_allclose(P5000, P5001)\n",
    "    return P5001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00016461 0.00022408 0.00068364 ... 0.00096515 0.00081828 0.00029638]\n",
      " [0.00016461 0.00022408 0.00068364 ... 0.00096515 0.00081828 0.00029638]\n",
      " [0.00016461 0.00022408 0.00068364 ... 0.00096515 0.00081828 0.00029638]\n",
      " ...\n",
      " [0.00016461 0.00022408 0.00068364 ... 0.00096515 0.00081828 0.00029638]\n",
      " [0.00016461 0.00022408 0.00068364 ... 0.00096515 0.00081828 0.00029638]\n",
      " [0.00016461 0.00022408 0.00068364 ... 0.00096515 0.00081828 0.00029638]]\n"
     ]
    }
   ],
   "source": [
    "probability_distribution = calculate_stationary_probabilities(adjacency_matrix)\n",
    "print(probability_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_summarization_paragraphs(distribution, map, num_paragraphs):\n",
    "    indices = distribution.argsort()[-(num_paragraphs):][::-1]\n",
    "    for index in indices:\n",
    "        print(\"Sentence:    \" + str(map[index][0]))\n",
    "        print(\"Probability: \" + str(distribution[index]))\n",
    "        print(\"---------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence:    \"I told you I went there,\" said Gatsby. \n",
      "Probability: 0.0020373417648373976\n",
      "---------------\n",
      "Sentence:    \"I want to know what Mr. Gatsby has to tell me.\" \n",
      "Probability: 0.0018836727069013088\n",
      "---------------\n",
      "Sentence:    \"I want to see you,\" said Tom intently. \"Get on the next train.\" \n",
      "Probability: 0.0018752426230309307\n",
      "---------------\n",
      "Sentence:    \"The only CRAZY I was was when I married him. I knew right away I made a mistake. He borrowed somebody's best suit to get married in and never even told me about it, and the man came after it one day when he was out. She looked around to see who was listening: \" 'Oh, is that your suit?' I  said. 'This is the first I ever heard about it.' But I gave it to him and then I  lay down and cried to beat the band all afternoon.\" \n",
      "Probability: 0.0018251801190002962\n",
      "---------------\n",
      "Sentence:    \"I know,\" he said definitely, \"I'm one of these trusting fellas and I don't think any harm to NObody, but when I get to know a thing I know it. It was the man in that car. She ran out to speak to him and he wouldn't stop.\" \n",
      "Probability: 0.0018216874220744815\n",
      "---------------\n",
      "Sentence:    \"I like her,\" said Daisy, \"I think she's lovely.\" \n",
      "Probability: 0.0018016191135945474\n",
      "---------------\n"
     ]
    }
   ],
   "source": [
    "output_summarization_paragraphs(probability_distribution[0], gatsby_map, 6)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
